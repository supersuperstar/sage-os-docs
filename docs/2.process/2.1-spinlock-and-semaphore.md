# 2.1 自旋锁和信号量

## 2.1.1 自旋锁

### 概述

自旋锁专为防止多处理器并发冲突而引入。自旋锁为实现保护共享资源提出了一种锁机制，在内核中大量应用于中断处理等部分。为了解决对某项资源的互斥使用，自旋锁在任何时刻最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。如果自旋锁已经被别的执行单元持有，调用者就一直循环等待该自旋锁。

### 自旋锁数据结构

```c
int efif[MAX_CPU] = {}; //cpu中断信息栈的起始信息
int ncli[MAX_CPU] = {}; //cpu中断信息栈的高度（计数器）
struct spinlock {
  bool lock_flag;    // 锁状态标记，当为真时表示已上锁
  const char *name;  // 锁名，用于输出日志
  int hold_cpuid;    // 当前使用锁的cpu，用于输出日志
};
```

### 接口说明

```c
//初始化一个自旋锁
void spin_init(spinlock_t *lk, const char *name);

//获得一个自旋锁
void spin_lock(spinlock_t *lk);

//释放一个自旋锁
void spin_unlock(spinlock_t *lk);

//返回当前cpu是否持有某个自旋锁
bool spin_holding(spinlock_t *lk);

//中断记录栈push功能
void spin_pushcli();

//中断记录栈pop功能
void spin_popcli();
```

### 设计思路

基于自旋锁的机制，我们可以设计一个最简单的自旋锁：

```c
void spin_lock(spinlock_t *lk)
{
	while (if(lk->lock_flag!=0)) {
    ;
  }
  lk->lock_flag = 1;
}
```

每次循环原子性的判断该锁是否被上锁：

- 如果没有则占用，跳出循环
- 如果被占用则继续循环（自旋）  
  需要解锁时原子性的将该锁状态符置 0 即可

这样的锁存在十分严重的缺点，也就是运行效率偶尔会十分低下。这是由于内核态切换、异常等原因经常会陷入中断状态。如果占用某自旋锁的进程陷入中断状态，该自旋锁也会一直被该进程占用，直到解除中断，从而导致其他希望占用该锁的进程在中断期间也一直自旋，造成整个系统并发程度降低。

自旋锁一般用于保护共享内存（或参数）的少量指令工作，如对某个公共值的加减（此功能指令只有一行），所以我们可以在 cpu 每次申请锁时关闭该 cpu 的中断，释放锁的时候再开中断。

```c
void spin_lock(spinlock_t *lk)
{
	interrupt colse()；
	while (if(lk->lock_flag!=0)) {
    ;
  }
  lk->lock_flag = 1;
}
```

这样处理似乎正确了，但其实还有问题，当我们需要修改两个以上共享参数时：

```c
lock(a);
lock(b);
- - - - - -
unlock(b);  //open interrupt
unlock(a);
```

我们会在第一次 unlock 时就开中断而可能陷入中断，而使此优化失去意义，所以我们对每个 cpu 可以引入一个栈来存储放入了多少锁，通过 push 增加锁，pop 弹出锁。  
此外，当我们申请锁的时候可能中断本来就被关闭了，而在最后一次弹出锁开中断则会导致原程序出现问题，所以我们选择用栈底存储 cpu 第一次增加锁时，关中断的原状态，在最后一次弹出锁时还原状态。

#### 申请锁的流程

```flow
st=>start: 接到申请锁请求
ed=>end: 结束申请流程
push=>operation: 压入中断信息栈
读取当前中断开关状态 i
ncli=>condition: cpu->ncli == 0
ncliy=>operation: cpu->efif 设置为 i
ncliplus=>operation: 当前cpu的ncli加一
xchg=>condition: atomic_xchg
lkhold=>operation: 更改hold_cpuid为当前cpu

st->push->ncli
ncli(yes)->ncliy->ncliplus
ncli(no)->ncliplus
ncliplus(right)->xchg
xchg(yes)->lkhold->ed
xchg(no)->xchg
```

#### 释放锁的流程

```flow
st=>start: 接到释放锁请求
ed=>end: 结束释放流程
lkhold=>operation: hold_cpuid 设为 -1；
lock_flag 设为 false；
将当前锁弹出中断信息栈；
当前cpu的ncli计数器减一
checkefif=>condition: cpu.ncli == 0
&&
cpu.efif == 1
setefif=>operation: 开中断

st->lkhold->checkefif
checkefif(yes)->setefif->ed
checkefif(no)->ed
```

### 设计细节

::: warning 警告
建议创建锁时使用 spin_init 函数初始化
:::
::: warning 警告
不建议在 `spin_lock(a)` 和 `spin_unlock(a)` 之间放置太多指令，中断关闭时间过长会出现问题，例如输入中断关闭过长会导致部分输入被吞
:::

#### 申请锁

我们 push 中断信息栈后，使用 `am` 提供的库函数 `atomic_xchg(int *addr, int newval) ` ，该库函数会原子性地监测 addr 是否不为 newval，并在不为 newval 的情况下改为 newval，并返回修改结果从而退出 while 循环。
::: danger 危险
注意自旋锁不能多次嵌套使用，如：

```
lock(a);
- - - - - -  //no unlock(a)
lock(a);
```

我们提供了 `spin_holding` 和申请时的 assert 检查这种情况，请在编写时注意
:::

#### 释放锁

我们使用 c++内联汇编函数 `asm volatile（）` 将锁状态置零后，pop 中断信息栈。

#### 监测持有人

我们提供了 `spin_holding（）` 接口可让当前进程判断是否持有该锁，assert 和内核常用该函数  
注意我们监测时需要关开中断，防止中断可能导致的问题

#### 中断信息栈

我们先建立一个中断栈示例，以 1 0 表示开中断 关中断：

```
    +---------------+
    |       0       |
    +---------------+
    |       0       |
    +---------------+
    |       0       |
    +---------------+
    |     1 / 0     | (栈底，记录最初的开关中断状态)
    +---------------+

```

观察发现我们其实并不需要一个栈，只需要一个计数器 ncli 去维护该 cpu 里含有多少锁（此计数器同时保证我们不需要按申请锁顺序释放锁）和一个 efif 去记录最初开关中断状态即可。  
所以我们最后使用一个计数器（ncli）组和 efif 组记录不同 cpu 的简化中断信息栈信息。  
使用 qemu 提供的库函数 `iset()` 开关中断

## 2.1.2 信号量

### 概述

信号量(Semaphore)，是在多进程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用。在进入一个关键代码段之前，进程必须获取一个信号量；一旦该关键代码段完成了，那么该进程必须释放信号量。其它想进入该关键代码段的进程必须等待直到第一个进程释放信号量。我们的信号量使用自旋锁作 mutex ，并添加了条件变量所需的等待功能和唤醒功能。

### 信号量数据结构

```
struct semaphore {
  spinlock_t lock;     // 该信号量的自旋锁（mutex）
  const char *name;    // 该信号量的名字
  volatile int value;  // 该信号量的值（条件/计数器）
};
```

### 接口说明

```c
// 信号量初始化，并初始化其自旋锁
void sem_init(sem_t *sem, const char *name, int value);

// 信号量wait操作，值非零时值减一，否则进程等待
void sem_wait(sem_t *sem);

// 信号量signal操作，值加一，并将该信号量下睡眠进程唤醒
void sem_signal(sem_t *sem);
```

### 设计思路

理解信号量原理，我们需要两个信号量函数即可应对大部分的并发模型。

#### sem_wait

sem_wait 使用自旋锁确保并发的正确性被保持，同时利用系统中断进行休眠，从而避免了“忙等”情况的出现。它的作用是从信号量的值减去一个“1”，但它永远会先等待该信号量为一个非零值才开始做减法：

- 如果你对一个值为 2 的信号量调用 `sem_wait()` ，进程将会继续执行，将信号量的值将减到 1。
- 如果对一个值为 0 的信号量调用 `sem_wait()` ，这个进程将会调用 `yield` 以自陷到中断处理程序中，相关处理子程序会设置其状态为 Sleep 并不再调度该进程，直到有其它进程发送 signal 后才会唤醒该进程。
- 如果有两个进程都在 `sem_wait()` 中等待同一个信号量变成非零值。那么当它被第三个进程增加 一个“1”时，沉睡进程中只有一个能够对信号量做减法并继续执行，另一个还留在循环并再次进入沉睡状态。

```flow
st=>start: 对传入信号量调用wait函数
ed=>end: 结束wait流程
semlock1=>operation: 申请当前信号量自旋锁
semvalue=>condition: sem->value <= 0
semulock1=>operation: 释放当前信号量自旋锁；
设置进程的wait_sem并休眠进程；
进程被外部 signal 激活
semvaluem=>operation: 当前信号量值减一
semulock2=>operation: 释放当前信号量自旋锁

st->semlock1->semvalue
semvalue(yes)->semulock1(left)->semvalue
semvalue(no)->semvaluem->semulock2->ed
```

#### sem_signal

同 sem_wait，该函数也需要大量原子操作，他的作用是将信号量的值加"1"。但因为节省资源需要，我们将等待该信号量值非零的进程全部沉睡，因此我们需要同时唤醒所有因为该信号量而沉睡的进程，竞争信号量的自旋锁，赢家得到使信号量的值减”1"的权利。

```flow
st=>start: signal
ed=>end: 结束
semvaluep=>operation: 当前信号量值加一
lookup=>condition: 进程队列
存在wait该信号量的进程
stateup=>operation: 唤醒该进程

st->semvaluep->lookup
lookup(yes)->stateup(right)->ed
lookup(no)->ed
```

### 设计细节

#### wait

wait 本身提供值减一的操作，但我们需要判断值非零才可进行操作。而因为会有多人消费一人生产的情况，当值为 1 时只有一个进程能抢到减一的权利，所以使用 `while (sem->value <= 0)` 的架构，以及对信号量本身的自旋锁的上锁，保证集体唤醒后只有信号量值大小的进程跳出循环，其他进程进入下一次循环进行沉睡。同时，进行沉睡的进程 wait_sem 会被标记为此信号量。

我们使用 `yield()` 使当前正在运行的进程进入等待状态，但进程可能会因为 `kmt_yield()` 检测当前进程有等待信号量而进入睡眠。

#### signal

我们将值增加的同时，需要唤醒那些因当前信号量值为零而被沉睡的进程（消费者）。 因为进程池采用链表形式，所以遍历一遍链表筛选 wait_sem 为当前信号量的进程，并将睡眠的进程唤醒：

```c
if (tp->state == ST_S) tp->state = ST_W;
```

接下来，该进程将会在下一次系统中断调度时有机会获得 CPU 时间。
